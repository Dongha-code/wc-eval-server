from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from gpt_eval_api_flow import (
    generate_next_step,
    load_step_context,
    generate_next_question,
    user_sessions
)
from gpt_function_schema import functions
import openai

app = Flask(__name__, static_url_path='/static', static_folder='static')
CORS(app)

client = openai.OpenAI()

# ÌÄ¥Ï¶à ÏãúÏûë (ÏÇ¨Ïö©Ïûê Ï¥àÍ∏∞Ìôî)
@app.route("/api/start", methods=["POST"])
def start_quiz():
    try:
        data = request.get_json()
        email = data.get("email")
        user_sessions[email] = {
            "step_sequence": [],
            "history": [],
            "current_index": 0,
        }
        return jsonify({"status": "initialized"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# Îã§Ïùå Î¨∏Ï†ú ÏöîÏ≤≠
@app.route("/api/next-question", methods=["GET"])
def next_question():
    try:
        email = request.args.get("email")
        current_index = int(request.args.get("index", 0))

        step = generate_next_step(email, current_index)
        if step is None:
            return jsonify({"complete": True})

        context = load_step_context(step)
        if context is None:
            return jsonify({"error": f"Context for {step} not found"})

        prompt = f"""Îã§ÏùåÏùÄ {step} Îã®Í≥ÑÏùò ÌïôÏäµ ÏΩòÌÖêÏ∏†ÏûÖÎãàÎã§. Ïù¥Î•º Î∞îÌÉïÏúºÎ°ú Ïã§Î¨¥ Ï†ÅÏö© Ï§ëÏã¨Ïùò Ïã¨Ìôî ÏÑúÏà†Ìòï Î¨∏Ï†úÎ•º 1Î¨∏Ìï≠ ÏÉùÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.
Ï°∞Í±¥:
- ÌïôÏäµÏûêÏùò Ïã§Î¨¥ Ï†ÅÏö© Îä•Î†•ÏùÑ ÌèâÍ∞ÄÌï† Ïàò ÏûàÎèÑÎ°ù Ïã§Ï†ú ÏÇ¨Î°Ä Í∏∞Î∞ò ÏßàÎ¨∏ÏúºÎ°ú Íµ¨ÏÑ±
- ÏΩòÌÖêÏ∏† Ïù¥Ìï¥ÎèÑÎ•º ÌååÏïÖÌï† Ïàò ÏûàÎèÑÎ°ù ÎπÑÌåêÏ†Å ÏÇ¨Í≥†Î•º Ïú†ÎèÑ
- Î¨∏Ï†úÎäî ÌïúÍµ≠Ïñ¥Î°ú Ï†úÍ≥µ"""

        question = generate_next_question(prompt, context)
        if question is None:
            return jsonify({"error": "Î¨∏Ï†ú ÏÉùÏÑ± Ïã§Ìå®"})

        return jsonify({
            "step": step,
            "question": question,
            "context": context,
            "complete": False
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ÎãµÏïà Ï†úÏ∂ú Î∞è ÌèâÍ∞Ä
@app.route("/api/submit-answer", methods=["POST"])
def submit_answer():
    try:
        data = request.get_json()
        email = data.get("email")
        user_answer = data.get("answer")
        current_index = data.get("index", 0)

        step = generate_next_step(email, current_index)
        context = load_step_context(step)

        if step is None or context is None:
            return jsonify({"complete": False, "feedback": {"error": "Î¨∏Ï†ú ÌèâÍ∞Ä Ï†ïÎ≥¥ ÎàÑÎùΩ"}})

        # GPT ÌèâÍ∞Ä ÏöîÏ≤≠
        messages = [
            {
                "role": "system",
                "content": f"{step} Î¨∏Ìï≠ Ï±ÑÏ†ê Í∏∞Ï§ÄÏóê Îî∞Îùº Îã§Ïùå ÎãµÏïàÏùÑ ÌèâÍ∞ÄÌïòÏÑ∏Ïöî. Í∏∞Ï§Ä: Ïù¥Ìï¥ÎèÑ, Ïã§Î¨¥ Ï†ÅÏö© Í∞ÄÎä•ÏÑ±, Íµ¨Ï≤¥ÏÑ±."
            },
            {"role": "user", "content": f"üìò Î¨∏Îß•: {context}\n\n‚úçÔ∏è ÌïôÏäµÏûê ÎãµÎ≥Ä: {user_answer}"}
        ]

        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages,
            temperature=0.5,
            functions=functions,
            function_call={"name": "evaluate_answer"},
        )

        function_args = response.choices[0].message.function_call.arguments
        feedback = json.loads(function_args)

        complete = (current_index + 1 >= 30)

        return jsonify({
            "complete": complete,
            "feedback": {
                "answer": user_answer,
                "question": data.get("question", ""),
                "step": step,
                **feedback,
            },
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# Ï†ïÏ†Å HTML ÏÑúÎπô
@app.route("/")
def root():
    return send_from_directory(app.static_folder, "quiz_ui_web.html")

