{
  "step": "STEP 5",
  "title": "데이터 변환 / 전송 / 성능",
  "sections": [
    "변환 태스크 설정 및 로그 포맷 처리",
    "전송 채널 구성: JDBC, Kafka, RabbitMQ, HTTP",
    "전송 실패 및 재시도 처리 방식",
    "성능 측정 기준: TPS, Kafka 처리량, 디스크 IOPS 등",
    "성능 테스트 실행 예시 및 설정 스크립트 가이드"
  ],
  "context": "[STEP 5-1] 변환 태스크 설정 및 로그 포맷 처리\n[STEP 5-2] 전송 채널 구성: JDBC, Kafka, RabbitMQ, HTTP\n[STEP 5-3] 전송 실패 및 재시도 처리 방식\n[STEP 5-4] 성능 측정 기준: TPS, Kafka 처리량, 디스크 IOPS 등\n[STEP 5-5] 성능 테스트 실행 예시 및 설정 스크립트 가이드\n[STEP 5-1] 변환 태스크 설정 및 로그 포맷 처리\n✅ 개념 요약\nWiseCollector는 수집된 로그를 외부 시스템에 전송하기 전에 변환 태스크(Transformation Task)를 통해 데이터를 재구성하고 불필요한 값을 제거하거나 필요한 필드를 가공합니다.\n변환 설정은\n필드 추출\n,\n데이터 타입 지정\n,\n조건부 필터링\n,\n샘플 테스트 기능\n등을 포함하고 있으며, DB 전송이나 실시간 분석에 적합한 형태로 데이터를 포맷팅합니다.\n✅ 변환 태스크 구성 요소\n항목\n설명\n태스크 ID\n유일한 식별자 (예:\nconvert_page_view\n)\n저장 경로\n변환된 로그 파일의 저장 위치\n필드 구성\n필드명, 데이터 타입, 출력 형식 설정\n필터 조건\n조건을 만족하는 로그만 변환 대상으로 지정\n시뮬레이션\n샘플 로그 기반으로 변환 결과 미리보기 가능\n✅ 로그 포맷 설정 예시\n{\n  \"event_type\": \"page_view\",\n  \"user_id\": \"U123456\",\n  \"timestamp\": \"2025-04-12T13:00:00.123Z\"\n}\n필드는 String, Number, Boolean, Timestamp 등으로 지정 가능\nTimestamp는\nunixTimeMillis\n→ ISO 8601 포맷으로 자동 변환 가능\n✅ 조건부 필터 예시\n특정 값이 존재할 경우에만 로그를 출력:\nIF event_type = \"click\" AND user_id IS NOT NULL\n필드가 null인 경우 로그 생략\n✅ 샘플 테스트 기능\n설정 후 UI에서 샘플 로그를 입력하면 결과를 실시간 미리보기 가능\n오탈자, 필드 누락, 필드명 충돌 등을 사전에 확인할 수 있음\n✅ 배치 처리 및 결과 저장 구조 (선택사항)\n변환 태스크는 일정 주기로 실행 가능 (배치 모드)\n저장 경로 예시:\n/data/logs/converted/YYYY/MM/DD/task_name.log\nJSON, CSV, AVRO 등 포맷별 저장도 가능\n📌 학습 체크포인트\n변환 태스크의 핵심 설정 항목 3가지를 말해볼 수 있나요?\n필터 조건은 변환 로직에 어떤 영향을 주며, 설정 예시는 어떤 형태인가요?\n샘플 테스트 기능은 어떤 실수를 예방해줄 수 있나요?\n로그 포맷을 정의할 때 데이터 타입을 지정하지 않으면 어떤 문제가 발생할 수 있나요?\n[STEP 5-2] 전송 채널 구성: JDBC, Kafka, RabbitMQ, HTTP\n✅ 개념 요약\nWiseCollector의 전송 구성은\n변환된 로그를 외부 시스템에 전달\n하기 위한 작업으로, 전송 채널(Sink)은 전송 목적지와 방식에 따라\nJDBC / Kafka / RabbitMQ / HTTP / AVRO\n등으로 구분됩니다.\n각 채널은 사용 목적에 따라 설정 항목과 처리 방식이 달라지며,\n전송 속도 및 안정성에 영향을 미칩니다.\n✅ 전송 채널 구성 요소\n구성 요소\n역할\nSource\n변환된 로그를 수집\nChannel\n로그를 임시 저장 (메모리 또는 파일)\nSink\n외부 시스템으로 로그를 전송 (JDBC, Kafka 등)\n✅ JDBC 채널\n데이터베이스(DB)로 전송할 때 사용\n연결정보 및 JDBC 드라이버\n가 필요\nagent1.sinks.jdbc-sink.type = jdbc\nagent1.sinks.jdbc-sink.driver = org.mariadb.jdbc.Driver\nagent1.sinks.jdbc-sink.url = jdbc:mariadb://localhost:3306/db\nagent1.sinks.jdbc-sink.username = user\nagent1.sinks.jdbc-sink.password = pass\nagent1.sinks.jdbc-sink.sql = INSERT INTO nlog_info (...) VALUES (...)\nJDBC 드라이버는 수동으로\n/base/flume/lib\n경로에 배치 필요\n✅ Kafka 채널\n메시지 큐 기반 대용량 분산 처리\n에 적합\n토픽, 브로커 주소, 파티션 설정 필요\nagent1.sinks.kafka-sink.type = kafka\nagent1.sinks.kafka-sink.brokerList = localhost:9092\nagent1.sinks.kafka-sink.topic = nlog_topic\nagent1.sinks.kafka-sink.serializer = json\nKafka 전송은 실시간 분석/모니터링 시스템과 연계에 효과적이며 TPS 1000 이상도 가능\n✅ RabbitMQ 채널\n비동기 메시지 큐 방식,\n지연 허용 시스템\n에 유리\n인증, 큐 이름, 가상 호스트 등 구성 필요\nagent1.sinks.rabbitmq-sink1.type = kr.nethru.ncollector.transport.flume.sink.rabbit.RabbitMQSink\nagent1.sinks.rabbitmq-sink1.hostname = localhost\nagent1.sinks.rabbitmq-sink1.port = 12345\nagent1.sinks.rabbitmq-sink1.username = user\nagent1.sinks.rabbitmq-sink1.password = pass\nagent1.sinks.rabbitmq-sink1.queuename = log_queue\nagent1.sinks.rabbitmq-sink1.batchsize = 100\nagent1.sinks.rabbitmq-sink1.deliverymode = 1\nconfirm\n옵션이\nfalse\n일 경우 빠르지만 손실 가능성 존재\n✅ HTTP 채널\nPOST 방식으로 외부 API 서버에 데이터 전송\n주로 수집 API 또는 RESTful 서비스와 연계할 때 사용\nagent1.sinks.http-sink.type = http\nagent1.sinks.http-sink.endpoint = http://api.company.com/nlog\nagent1.sinks.http-sink.headers = Content-Type:application/json\n네트워크 불안정 시 재시도/오류 처리 설정 필요\n✅ 채널 구성 방식 (선택사항)\n채널\n특징\nMemory Channel\n빠르지만 서버 재시작 시 데이터 유실 가능\nFile Channel\n안정성 높지만 상대적으로 느림\nKafka Channel\n외부 연계용, 확장성 뛰어남\n📌 학습 체크포인트\nJDBC 채널을 사용하기 위해 반드시 필요한 설정 요소는 무엇인가요?\nKafka를 사용할 때 브로커 주소 외에 반드시 지정해야 할 항목은 무엇인가요?\nRabbitMQ 채널의\nbatchsize\n와\ndeliverymode\n는 각각 어떤 역할을 하나요?\nHTTP 채널은 어떤 상황에서 적합하고, 어떤 설정이 특히 중요할까요?\n[STEP 5-3] 전송 실패 및 재시도 처리 방식\n✅ 개념 요약\nWiseCollector의 전송 모듈은 외부 시스템으로 로그를 전송하는 과정에서\n네트워크 불안정, 연결 오류, 메시지 포맷 문제\n등으로 인해 실패가 발생할 수 있습니다.\n이를 대비해\nbatch size, confirm 설정, delivery mode\n등 다양한 전송 안정성 설정이 지원됩니다.\n특히\nRabbitMQSink\n는 재전송 여부를 설정할 수 있는 핵심 파라미터를 포함하고 있으며, 재시도 실패 시 로그 분석이 필수입니다.\n✅ 주요 재전송 관련 설정 항목 (RabbitMQSink 기준)\n항목\n설명\nconfirm\n전송 후 송신 성공 여부 확인 여부 (true/false)\ndeliverymode\n1: 휘발성, 2: 디스크 저장 (성능 ↔ 안정성 트레이드오프)\nbatchsize\n한 번에 송신할 메시지 개수\nconnectiontimeout\n서버 접속 또는 confirm 응답 대기 시간 (ms)\n💡 예시 설정\nagent1.sinks.rabbitmq-sink1.confirm = true\nagent1.sinks.rabbitmq-sink1.deliverymode = 2\nagent1.sinks.rabbitmq-sink1.batchsize = 100\nagent1.sinks.rabbitmq-sink1.connectiontimeout = 5000\n✅ 설정별 의미와 유의점\nconfirm=true\n:\n→ 송신 결과를 ACK/NACK로 확인함 → 안정성↑, 성능↓\n→\nfalse\n로 하면\n성능은 좋아지나 데이터 유실 가능성 존재\ndeliverymode=2\n:\n→ 디스크 저장이 보장되나 I/O 병목이 발생할 수 있음\n→ 일반적으로는 휘발성(1)을 사용하고,\n중요 로그\n는\n2\n로 설정\nbatchsize=100\n:\n→ 대량 전송 시 전송 횟수 감소로 TPS 향상\n→ 단, 실패 시 손실 메시지도 커질 수 있어 적정값 설정 필요\n✅ 전송 실패 로그 예시 (문서 기반)\n오류 메시지\n원인\nserver disconnected before a response was received\nconfirm 응답 없음\nSpace for commit to queue couldn't be acquired\n채널 메모리 부족\nBroker may not be available\nKafka 서버 비가용 상태\ndelivery failed - retrying\n메시지 전송 실패로 재시도 시도\n✅ 전송 실패 시 대응 전략 (선택사항)\n파일 채널 사용\nFileChannel 사용 시 서버 재기동 후 재처리 가능\n장애 조치용 로그 백업\n실패한 전송 로그를 별도 위치에 백업하도록 설정\n경고 알림 연계\nSlack, Email 알림과 연동해 장애 발생 시 실시간 감지\n📌 학습 체크포인트\n전송 실패를 방지하거나 복구하기 위한 대표 설정값은 무엇인가요?\nconfirm=false\n로 설정했을 때의 장점과 단점은 무엇인가요?\ndeliverymode\n가\n1\n일 때와\n2\n일 때 시스템에 미치는 영향은 어떻게 다르나요?\n전송 실패 로그에서 자주 등장하는 메시지와 원인을 하나 이상 설명해 보세요.\n[STEP 5-4] 성능 측정 기준: TPS, Kafka 처리량, 디스크 IOPS 등\n✅ 개념 요약\nWiseCollector의 데이터 전송 성능은 주로\nTPS (Transactions Per Second)\n,\nKafka 처리량\n,\n디스크 IOPS\n등의 기준으로 측정됩니다.\n이는 전송 효율성을 평가하고 적정 설정값을 찾는 데 핵심 지표로 활용되며, 특히\nbatch size, transferPositionSaveDenominator\n등의 설정이 직접적인 영향을 미칩니다.\n✅ 공식 성능 수치 (문서 기준)\n구분\n성능 (TPS)\n수집\n4,000 TPS\n변환\n4,000 TPS (기본 1,000)\nHTTP/Kafka/JDBC\n약 1,000 TPS\nAVRO\n최대 4,000 TPS\n✅ 실제 전송 성능 테스트 결과 (AVRO 기준)\n테스트 케이스\n로그 파일 수\nTPS 결과\nCASE 1\n1개 (10만라인)\n1,400 TPS\nCASE 2\n2개\n2,500 TPS\nCASE 3\n3개\n2,850 TPS\nCASE 4 (옵션 적용:\ntransferposition=100\n)\n3개\n23,000 TPS\n✅ 성능 향상을 위한 주요 설정\nbatchSize\nSink가 한 번에 처리할 수 있는 데이터 건수\n크면 TPS는 올라가지만, 실패 시 손실도 큼\ntransport.sinks.kafka.batch-size=1000\ntransferPositionSaveDenominator\n몇 줄마다 전송 위치를 기록할지 지정\n클수록 디스크 쓰기 감소 → TPS 향상 가능\ntransferPositionSaveDenominator=100\npositionCommitCount\n변환 시 로그 커밋 주기 설정 (변환 태스크에 적용)\npositionCommitCount=100\n단, 재시작 시 커밋되지 않은 위치부터 재시도되어\n중복 처리 가능성 존재\n✅ 디스크 IOPS란?\nIOPS (Input/Output Operations per Second)\n: 초당 디스크 I/O 수행 횟수\n💡 계산 예시 (블럭 단위: 4KiB 기준)\nIOPS = 초당 전송량(MiB) / 4KiB\n예: 16,000 IOPS → 약 62.5 MiB/s 처리 가능\n(16,000 * 4KiB = 64,000 KiB/s ≒ 62.5 MiB/s)\n디스크 성능이 낮은 경우 TPS가 급감할 수 있음\n📌 학습 체크포인트\nTPS 기준에서 수집, 변환, 전송 각각의 공식 성능 수치를 기억하고 있나요?\nbatchSize\n와\ntransferPositionSaveDenominator\n설정은 어떤 방식으로 TPS에 영향을 미치나요?\npositionCommitCount\n설정을 잘못 사용하면 어떤 문제가 발생할 수 있나요?\n디스크 IOPS의 정의와, 이를 통해 어떤 성능 수치를 유추할 수 있는지 설명할 수 있나요?\n[STEP 5-5] 성능 테스트 실행 예시 및 설정 스크립트 가이드\n✅ 개념 요약\nWiseCollector의 전송 성능과 서버 응답 안정성을 테스트하기 위해 **부하 생성 도구(JMeter, curl 등)**를 이용해 시뮬레이션을 수행합니다.\n테스트 조건 설정과 테스트 스크립트는 시스템 한계점 확인, TPS 향상 설정 검증, 전송 지연 탐지 등의 목적으로 사용됩니다.\n✅ JMeter 기반 부하 테스트\n💡 기본 설정 항목\n설정\n설명\nThread Group\n동시에 실행할 사용자 수\nRamp-up Period\n각 스레드를 몇 초 간격으로 실행할지\nLoop Count\n각 스레드가 몇 번 반복할지 (무한 가능)\nHTTP Request\n요청 대상 서버 IP, 포트, 경로 설정\nNumber of Threads: 100  \nRamp-up Period: 10 (10초 동안 100명 실행)  \nLoop Count: Infinite\n💡 예시 JMeter 명령어 (리눅스 non-GUI 방식)\n./jmeter.sh -n -t ./test_plan.jmx -l ./test_result.log\n-n\n: non-GUI 모드 실행\n-t\n: JMX 테스트 시나리오 파일\n-l\n: 로그 출력 파일 경로\n💡 테스트 설정 파일은 GUI에서 만든 후\n.jmx\n파일로 저장해 CLI에서 사용\n✅ Bash 기반 curl 테스트 스크립트 예시\n💡 샘플: 1초당 100건 전송\n#!/bin/bash\nrequests_per_second=100\n\ngenerate_random_number() {\n  echo $((RANDOM % 9000000000 + 1000000000))\n}\n\nmake_requests() {\n  for ((i=0; i<$requests_per_second; i++)); do\n    random_value=$(generate_random_number)\n    url=\"https://work.nethru.co.kr/nlog/log/event?v=${random_value}\"\n    curl -s \"$url\" &\n  done\n}\n\nwhile true; do\n  make_requests\n  sleep 1\ndone\n이 스크립트는 초당 요청 수를 기준으로 계속 부하를 생성합니다\n✅ 테스트 결과 확인 항목\n항목\n설명\nTPS\n초당 전송 요청 수 확인\n평균 응답 시간\n각 요청의 평균 응답 소요시간\n오류율\n요청 실패율 (%)\nCPU / Memory / Network 사용량\n서버 측 자원 소비 분석 지표\n📌 학습 체크포인트\nJMeter 설정 항목 중 사용자 수, 루프 횟수, 요청 경로는 각각 어디에 정의되나요?\n리눅스에서 GUI 없이 JMeter를 실행하려면 어떤 명령어를 사용하나요?\ncurl을 활용한 부하 테스트는 어떤 원리로 동작하며, 병렬 요청은 어떻게 처리되나요?\nTPS, 오류율, 응답 시간 외에 성능 테스트 결과에서 점검해야 할 추가 지표는 무엇인가요?"
}