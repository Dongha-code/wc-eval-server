import json
import os
from openai import OpenAI
from dotenv import load_dotenv
from gpt_function_schema import quiz_function_definitions

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def load_context_for_step(step: str) -> str:
    filename = f"step_{step.split()[-1]}.json"
    with open(filename, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data["context"]

def generate_question(step: str):
    try:
        context = load_context_for_step(step)
        print(f"\nğŸ“˜ [STEP]: {step}")
        print(f"ğŸ“„ [CONTEXT ê¸¸ì´]: {len(context)}")

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” WiseCollector 2.0 ì§„ë‹¨ ë¬¸ì œ ì¶œì œìì•¼."},
                {"role": "user", "content": f"{step} ë‚´ìš© ê¸°ë°˜ ì‹¤ë¬´í˜• ë¬¸ì œë¥¼ ìƒì„±í•´ì¤˜:\n\n{context}"}
            ],
            functions=quiz_function_definitions,
            function_call={"name": "generate_quiz_question"},
            timeout=10
        )

        message = response.choices[0].message
        print(f"ğŸ“¨ [GPT ì‘ë‹µ role]: {message.role}")
        print(f"ğŸ“¨ [GPT function_call]: {message.function_call}")

        call = message.function_call
        if not call or not call.arguments:
            raise ValueError("GPTê°€ function_call ë˜ëŠ” argumentsë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        result = json.loads(call.arguments)
        if not result.get("question"):
            raise ValueError("GPT ì‘ë‹µì— question í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        return result

    except Exception as e:
        print(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨ ({step}):", e)
        return {
            "question": f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}",
            "choices": [],
            "step": step
        }

def evaluate_answer(question: str, answer: str, step: str, correct=""):
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„Œ êµìœ¡ í‰ê°€ìì•¼. ì‚¬ìš©ì ì‘ë‹µì„ í‰ê°€í•˜ê³  í”¼ë“œë°±ì„ ì¤˜."},
                {"role": "user", "content": f"ë¬¸ì œ: {question}\në‹µë³€: {answer}\nëª¨ë²” ë‹µì•ˆ: {correct}"}
            ],
            functions=quiz_function_definitions,
            function_call={"name": "submit_answer"},
            timeout=10
        )
        return json.loads(response.choices[0].message.function_call.arguments)
    except Exception as e:
        print(f"âŒ ë‹µì•ˆ í‰ê°€ ì‹¤íŒ¨ ({step}):", e)
        return {"feedback": f"âŒ í‰ê°€ ì‹¤íŒ¨: {str(e)}", "step": step}

def generate_report(name: str, email: str, answers: list):
    try:
        messages = [
            {"role": "system", "content": "ë„Œ ì§„ë‹¨ ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” GPTì•¼."},
            {"role": "user", "content": f"ë‹¤ìŒì€ {name}({email})ì˜ ì§„ë‹¨ ì‘ë‹µì´ì•¼. ìš”ì•½í•´ì¤˜.\n\n{json.dumps(answers, ensure_ascii=False)}"}
        ]
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            functions=quiz_function_definitions,
            function_call={"name": "generate_diagnostic_report"},
            temperature=0.7,
            timeout=10
        )
        return json.loads(response.choices[0].message.function_call.arguments)
    except Exception as e:
        print("âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨:", e)
        return {"report": f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}"}
