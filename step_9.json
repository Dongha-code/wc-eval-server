{
  "step": "STEP 9",
  "title": "성능 테스트 및 운영 모니터링",
  "sections": [
    "JMeter, AB, Kafka 기반 성능 테스트 구성",
    "로그 처리량 및 시스템 자원 사용량 분석",
    "시스템 로그 레벨 및 장애 시나리오 대응",
    "운영 모니터링 설정: 통계 반영 주기 및 데이터 구조",
    "장애 감지 및 복구 프로세스 예시"
  ],
  "context": "[STEP 9-1] JMeter, AB, Kafka 기반 성능 테스트 구성\n[STEP 9-2] 로그 처리량(TPS) 및 시스템 리소스 분석\n[STEP 9-3] 시스템 로그 레벨 및 장애 시나리오 대응\n[STEP 9-4] 운영 모니터링 설정: 통계 반영 주기 및 데이터 구조\n[STEP 9-5] 장애 감지 및 복구 프로세스 예시\n[STEP 9-1] JMeter, AB, Kafka 기반 성능 테스트 구성\n✅ 개념 요약\nWiseCollector는 실시간 로그를 수집하고 전송하는 구조이기 때문에,\nTPS(Transactions Per Second), 응답 시간, 에러율\n등을 측정하는 성능 테스트가 필수적입니다.\n가장 널리 쓰이는 도구는\nApache JMeter\n,\nApache Bench (AB)\n, 그리고\nKafka 기반 전송 테스트\n입니다.\n✅ JMeter를 활용한 테스트 구성\n💡 CLI 모드 실행 명령어\n./jmeter.sh -n -t ./test_plan.jmx -l ./test_result.log\n옵션\n설명\n-n\nNon-GUI 모드 실행\n-t\nJMX 테스트 계획 파일 경로\n-l\n결과 로그 저장 파일 경로\n💡 구성 항목\nThread Group: 사용자 수 설정\nLoop Count: 요청 반복 횟수\nHTTP Sampler: 수집 서버 URL 및 파라미터 입력\n💡 테스트 항목 예시\nUsers: 100  \nLoop: 1000  \nRamp-up: 5s\n💡 각 Thread는 동시에 요청을 보내어, 실제 부하 조건을 시뮬레이션합니다\n✅ Apache Bench(AB)를 이용한 부하 테스트\n💡 설치 및 기본 명령\nsudo yum install httpd-tools\n\nab -n 1000 -c 10 https://work.nethru.co.kr/nlog/log/event?s=test\n옵션\n설명\n-n\n총 요청 수\n-c\n동시 접속자 수\n-t\n최대 수행 시간 (초)\n💡 간단한 성능 시뮬레이션 및\n단일 URL 테스트에 적합\n하며, TLS 적용 가능\n✅ Kafka 기반 전송 성능 테스트\n💡 실측 TPS 테스트 사례\nCASE\n전송량\n옵션 설정\nTPS 결과\nCASE 3\n3개 로그 파일\n기본 설정\n2,850 TPS\nCASE 4\n3개 파일\ntransferposition=100\n23,000 TPS\n💡 핵심 설정 항목\ntransferPositionSaveDenominator=100\nbatchSize=1000\ntransferPositionSaveDenominator\n: 저장 위치 기록 빈도 (값이 작을수록 TPS 하락)\nbatchSize\n: Kafka sink에서 일괄 전송 수량\n📌 학습 체크포인트\nJMeter를 비GUI로 실행할 때 필요한 명령어는 무엇인가요?\nAB 테스트에서\n-n\n,\n-c\n,\n-t\n는 각각 어떤 역할을 하나요?\nKafka TPS를 향상시키기 위해 조정 가능한 설정 항목은 무엇인가요?\n실측 TPS 테스트에서\ntransferposition=100\n설정은 어떤 영향을 미쳤나요?\n[STEP 9-2] 로그 처리량(TPS) 및 시스템 리소스 분석\n✅ 개념 요약\nWiseCollector 운영 중 시스템의 안정성과 처리 효율을 점검하기 위해서는\nTPS(초당 로그 처리 건수)\n,\nCPU/Memory 사용량\n,\n디스크 IOPS\n,\n전송 처리 지연\n등 여러 지표를 함께 분석해야 합니다.\n이는 서버 병목 원인을 사전 식별하거나 성능 한계를 명확히 인식하는 데 도움이 됩니다.\n✅ TPS 기준 측정\n💡 정의:\nTransactions Per Second (TPS)\n: 단위 시간(1초)당 처리된 로그 수\n💡 측정 기준:\n수집 TPS\n: 로그 요청 → 수집 태스크까지 도달 건수\n변환 TPS\n: 수집 → 변환 태스크로 전달되어 포맷 처리 완료된 건수\n전송 TPS\n: 변환 → 외부 시스템으로 실제 전송 완료된 건수\n💡 예시:\n테스트\nTPS 수치\nCASE1 (파일 1개)\n약 1,400 TPS\nCASE3 (파일 3개)\n약 2,850 TPS\nCASE4 (옵션 최적화 시)\n23,000 TPS\n✅ CPU / Memory 사용량\n💡 측정 방법\n리눅스 기본 명령어:\ntop\nhtop\nfree -m\n태스크 별 리소스:\n수집 에이전트 (agent_server)\n변환 태스크 (converter)\n전송 모듈 (sink)\nKafka Consumer 등 외부 연계 모듈\n💡 CPU 100% 근접 시 수집 중단 발생 가능 → 부하 분산, batchSize 조정 고려\n✅ 디스크 IOPS 분석\n💡 IOPS 정의\nIOPS\n(Input/Output Operations Per Second): 초당 디스크 I/O 작업 수\n💡 예시 계산 (블럭크기 4KiB 기준):\nIOPS = 초당 전송량 / 블럭 크기\n→ 16,000 IOPS × 4KiB = 64,000 KiB/s = 약 62.5 MiB/s\n고성능 전송을 위해\nSSD 또는 NVMe 기반 디스크 권장\nKafka 기반 실시간 처리량은 디스크 IOPS에 강하게 영향을 받음\n✅ 모니터링 통계 기반 수집량 확인 (보완용)\n수집 → 변환 → 전송 단계별 처리 건수 및 실패율 모니터링\n주요 항목:\n누적 로깅 건수\n변환 성공/실패 건수\n전송 실패율, 지연율\n에이전트 리소스 사용률\n📌 학습 체크포인트\nTPS 측정 시 수집, 변환, 전송의 각 단계별 의미는 어떻게 구분되나요?\nCPU 사용률 100% 상황이 지속되면 어떤 문제가 발생하며, 해결을 위한 설정 항목은?\nIOPS의 정의와 계산 방법은 무엇이며, 실제 운영에서 어떤 의미를 가지나요?\n로그 처리량 외 어떤 시스템 지표들이 함께 고려되어야 운영 진단이 가능한가요?\n[STEP 9-3] 시스템 로그 레벨 및 장애 시나리오 대응\n✅ 개념 요약\nWiseCollector는 각 태스크(agent, manager, converter, transport 등)에 대해 로그 백엔드 설정 파일(logback.xml, log4j2.xml 등)을 활용하여\n로그 레벨, 보존 기간, 출력 방식(STDOUT)\n등을 설정할 수 있으며, 장애 발생 시에는\n적절한 로그 레벨과 경로 설정\n이 원인 파악의 핵심입니다.\n✅ 로그 레벨 설정 방법\n💡 logback.xml 예시 (agent, converter, manager 공통)\n<root level=\"INFO\">\n  <appender-ref ref=\"LOGFILE\"/>\n</root>\n레벨\n의미\nDEBUG\n개발 및 디버깅용 상세 로그\nINFO\n기본 운영 상태, 성공 처리 내역\nWARN\n경고 메시지 (예: 조건 미충족)\nERROR\n실행 중 예외 발생, 처리는 완료됨\nCRIT / ALERT / EMERG\n시스템 장애, 서비스 영향 발생 수준\n💡 전송 태스크 (transport) log4j2.xml 예시\n<Root level=\"WARN\">\n  <AppenderRef ref=\"Console\"/>\n</Root>\n운영 중에는\nINFO\n또는\nWARN\n을 권장하며,\n디버깅 시 일시적으로\nDEBUG\n로 설정\n과도한 DEBUG 사용 시 로그 폭증 → 디스크 I/O 과부하 유발\n✅ STDOUT 로그 설정\n콘솔로 직접 로그를 출력하여, 도커/클라우드 환경에서 로그 수집 도구와 연계 가능\nstdout=true\nconsoleDir=/home/centos/logs\nSTDOUT는 일반 로그 파일보다\n실시간 모니터링에 유리\n단, 디스크 저장은 불가하므로\n파일 백업은 별도 필요\n✅ 장애 발생 시 로그 분석 시나리오\n유형\n징후\n확인 방법\n로그 미전송\n로그 없음, 대시보드 공백\nsink.log\n또는\nnlog-server.log\n에서 error or timeout\n중복 로그\n이벤트당 로그 2건 이상\nfireUserDefined\n다중 호출 여부 확인, 트리거 조건 확인\n변환 오류\n수집은 되나 전송 안됨\nconverter.log\n에서 필드 누락, JSON 변환 실패 메시지\n접속 불가\n로그인 실패, 403 오류\nmanager.log\n에 접근 거부 기록, IP 제한 여부 확인\n📌 실무에서의 팁 (선택사항)\n로그 레벨을\nERROR\n이하로 유지하면서, 특정 태스크에만\nDEBUG\n설정하는 방식 추천\nlogrotate\n,\nmaxHistoryDays\n,\nMaxBackupIndex\n등 설정을 통해\n로그 저장 용량 제어\n필수\n장애 시\n가장 최근 파일 + ERROR 키워드\n기반으로 탐색 필터링 수행\n📌 학습 체크포인트\n로그 레벨 중\nINFO\n,\nWARN\n,\nERROR\n,\nDEBUG\n는 각각 어떤 상황에서 사용되나요?\nSTDOUT 로그는 어떤 환경에서 활용되며, 장단점은 무엇인가요?\n장애 발생 시 sink, converter, manager 로그는 각각 어떤 항목을 우선적으로 확인해야 하나요?\n로그 과다 발생 방지를 위한 설정 항목은 어떤 것이 있나요?\n[STEP 9-4] 운영 모니터링 설정: 통계 반영 주기 및 데이터 구조\n✅ 개념 요약\nWiseCollector는 수집 → 변환 → 전송 전 과정에 대해\n모니터링 통계 데이터를 주기적으로 저장\n합니다.\n해당 데이터는 관리자 화면에서 확인할 수 있으며,\n당일 통계는 태스크 폴더에서 직접\n,\n과거 통계는 매니저 폴더에 집계되어 저장\n됩니다.\n또한, REST API를 통해 외부 연계도 가능합니다.\n✅ 통계 반영 주기 설정\n대시보드에서는 10초마다 통계 데이터 요청 후 갱신\n수집/변환/전송 화면에서는\n페이지 진입 시 1회만 통계 반영\n대시보드: 10초 간격\n수집/변환/전송 태스크 화면: 진입 시 1회 요청\n실시간 대시보드 구성 시, 주기 설정을 통해 과도한 리소스 사용 방지 가능\n✅ 통계 데이터 저장 구조\n💡 태스크별 통계 파일 (당일 데이터)\n{태스크설치경로}/monitor/metric.yyyymmdd  → 처리 건수\n{태스크설치경로}/monitor/usage.yyyymmdd   → 시스템 자원 정보\n💡 매니저 집계 통계 (과거 날짜)\n{매니저설치경로}/manager/works/data/{yyyymmdd}/{태스크ID}/tasktrend.txt    → 처리 건수\n{매니저설치경로}/manager/works/data/{yyyymmdd}/{태스크ID}/processtrend.txt → 시스템 사용량\n오늘 데이터는\n태스크 내 통계파일\n기준,\n이전 데이터는\n매니저 폴더에 집계 파일로 저장\n✅ 모니터링 API 연동 구조 (선택사항)\n태스크별 처리량, 전송 건수 등을 API로 직접 조회 가능\n요청 방식: HTTP GET 또는 POST\n출력 포맷: JSON\n💡 예시 요청\nGET /api/monitoring/task?taskId=agent1_transport1&date=20250410\n💡 응답\n{\n  \"taskId\": \"agent1_transport1\",\n  \"date\": \"20250410\",\n  \"metrics\": {\n    \"input\": 1432,\n    \"output\": 1412,\n    \"fail\": 20\n  }\n}\n모니터링 API는\n외부 대시보드(Grafana, Kibana 등)와 연동\n가능\n📌 학습 체크포인트\nWiseCollector 모니터링 통계는 대시보드에서 몇 초마다 업데이트되며, 수집/변환/전송 화면에서는 어떤 방식으로 반영되나요?\n당일 통계와 과거 통계는 각각 어떤 경로에 저장되며, 주요 파일명은 어떻게 구성되나요?\n태스크 단위 통계와 매니저 통계는 어떤 차이점이 있나요?\n외부 모니터링 도구와 연동 시 사용할 수 있는 API는 어떤 방식으로 동작하나요?\n[STEP 9-5] 장애 감지 및 복구 프로세스 예시\n✅ 개념 요약\nWiseCollector는 수집부터 전송까지 여러 모듈이 연계되어 작동하기 때문에, 문제 발생 시\n장애 유형을 빠르게 진단하고 복구 흐름에 따라 대응\n하는 것이 중요합니다.\n장애는 태깅 로직, 전송 실패, 타이밍 이슈, 호환성 오류, 권한 문제 등 다양한 원인으로 발생할 수 있습니다.\n✅ 장애 유형별 감지 기준 및 주요 증상\n유형\n증상\n주요 원인\n로그 누락\n로그 미수집 or 파라미터 일부 누락\n타이밍 이슈, 변수 미할당,\nsetTimeout\n필요\n중복 로그\n동일 이벤트가 여러 번 전송됨\nfireUserDefined 반복 호출, OR 조건 충돌\n전송 실패\n수집됨 → 전송 안 됨\n변환 실패, 전송 채널 오류, 전송 timeout\n미리보기 실패\nPreview 동작 안함, 로그 안 뜸\n트리거 설정 오류, 변수 누락, 브라우저 보안\n변환 오류\nCSV 파싱 실패, JSON 오류\n특수문자, 개행, 잘못된 포맷\n✅ 복구 시나리오\n💡 로그 누락 – 변수 미존재 or 타이밍 미스\nif (!window.userId) {\n  window.addEventListener(\"NTMREADY\", () => {\n    Ntm.Variable.addOnParam({ userId: window.userId });\n  });\n}\n페이지 진입 시 변수 로딩 안 된 경우:\nNTMREADY\n이벤트 활용\nsetTimeout 사용은 권장되지 않음 (성능 저하 유발)\n💡 전송 실패 – 전송 태스크 리셋\n변환 결과가 문제 없는 경우, 수동 재전송 가능\nsh restart_transport.sh\nsink 오류 로그 확인 → Kafka 연결, batch size 설정 재점검\n💡Preview 미출력 시 점검 항목\n항목\n확인 방법\n스크립트 로딩 여부\n개발자도구 Network 탭에서\nntm.js\nfireUserDefined 호출 여부\n콘솔 로그 출력 확인\n태그 상태\n관리자 UI → 트리거 등록 여부\n💡 중복 로그 – SPA 환경\nfireUserDefined()\n가 SPA 페이지 전환마다 자동 호출되는 경우:\nif (!sessionStorage.getItem(\"click_once\")) {\n  sessionStorage.setItem(\"click_once\", true);\n  Ntm.Event.fireUserDefined(\"custom_click\");\n}\nReact, Vue 등은 페이지마다\ninit 시점에서 호출을 통제해야 함\n📌 실무에서의 팁 (선택사항)\n전송 실패 시 파일 백업:\n/logs/error/\n하위 디렉토리 확인\n미리보기 테스트는\nNtm.Plugin.nlogger.download(\"test_log\")\n로 로그 확인\nSlack / 이메일 연동 등 장애 감지 알림 체계 병행 구축\n📌 학습 체크포인트\nPreview 모드에서 로그가 출력되지 않을 경우 어떤 항목을 먼저 점검해야 하나요?\n전송 실패가 발생했을 때 가장 먼저 점검해야 할 파일이나 로그는 어디에 위치하나요?\nSPA 환경에서 중복 로그가 발생하는 주요 원인은 무엇이며, 어떻게 해결하나요?\n변수 미정의로 로그 누락이 발생하는 경우, 어떤 이벤트를 활용하여 지연 실행할 수 있나요?"
}