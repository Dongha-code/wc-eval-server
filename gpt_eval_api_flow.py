import random
import json
import openai
from openai import OpenAI

client = OpenAI()

# ì‚¬ìš©ìë³„ ìƒíƒœ ì €ì¥
user_sessions = {}

def initialize_step_sequence():
    step_labels = [f"STEP {i}" for i in range(1, 10)]
    sequence = []
    while len(sequence) < 30:
        random.shuffle(step_labels)
        sequence.extend(step_labels)
    return sequence[:30]

# âœ… ì‚¬ìš©ì ì´ˆê¸°í™”
def init_user_session(name, email):
    user_sessions[email] = {
        "name": name,
        "email": email,
        "step_sequence": initialize_step_sequence(),
        "current_index": 0,
        "answers": []
    }

# âœ… ë‹¤ìŒ STEP ë°˜í™˜
def generate_next_step(email, current_index):
    if email not in user_sessions:
        return None
    sequence = user_sessions[email]["step_sequence"]
    if current_index >= len(sequence):
        return None
    return sequence[current_index]

# âœ… STEPë³„ JSON context ë¡œë”©
def load_step_context(step_label):
    filename = f"{step_label.lower().replace(' ', '_')}.json"
    try:
        with open(filename, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data["context"]
    except Exception:
        return None

# âœ… ë¬¸ì œ ìƒì„±
def generate_next_question(prompt_template, context):
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": prompt_template},
                {"role": "user", "content": context}
            ],
            temperature=0.7,
            max_tokens=800
        )
        return response.choices[0].message.content
    except Exception:
        return None

# âœ… ë‹µë³€ í‰ê°€ í•¨ìˆ˜ (Function Calling ê¸°ë°˜)
def evaluate_answer(answer, context=None, step="STEP ?"):
    prompt = f"""
ë‹¤ìŒì€ WiseCollector í•™ìŠµìê°€ ì‘ì„±í•œ ë‹µë³€ì…ë‹ˆë‹¤. ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€í•´ì£¼ì„¸ìš”:
- ë‹µë³€ì˜ ì •í™•ì„±
- ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±
- ì„œìˆ ì˜ êµ¬ì²´ì„±
- í•™ìŠµ ë‚´ìš©ì˜ ë°˜ì˜ ì—¬ë¶€

ë¬¸í•­ STEP: {step}
"""
    try:
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"ğŸ“ í•™ìŠµì ë‹µë³€: {answer}"}
        ]

        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages,
            temperature=0.5,
            functions=[
                {
                    "name": "evaluate_answer",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "score": {"type": "integer"},
                            "feedback": {"type": "string"},
                            "recommendation": {"type": "string"},
                            "level": {
                                "type": "string",
                                "enum": ["Level 1", "Level 2", "Level 3", "Level 4", "Level 5"]
                            }
                        },
                        "required": ["score", "feedback", "recommendation", "level"]
                    }
                }
            ],
            function_call={"name": "evaluate_answer"}
        )

        args = response.choices[0].message.function_call.arguments
        return json.loads(args)

    except Exception as e:
        return {"error": str(e)}

# âœ… ì§„ë‹¨ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
def generate_report():
    return {
        "message": "ì§„ë‹¨ ë¦¬í¬íŠ¸ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    }
